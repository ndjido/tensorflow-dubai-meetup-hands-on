{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Loading MNIST Data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = '/Users/ndjido/Documents/Davidson_Consulting/TF_DL_Meetup/Demo/Shallow_MNIST/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 28 * 28])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary function ==> TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/' + name, mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev/' + name , stddev)\n",
    "        tf.summary.scalar('max/' + name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/' + name, tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram/' + name, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Shallow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Model\"):\n",
    "    W = tf.Variable(tf.zeros([28 * 28, 10]), name=\"W\")\n",
    "    variable_summaries(W, 'Weights')\n",
    "    b = tf.Variable(tf.zeros([10]), name=\"b\")\n",
    "    variable_summaries(b, 'Biases')\n",
    "    y_model = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy_2:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_model, labels=y_))\n",
    "\n",
    "tf.summary.scalar(\"cross_entropy\", cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Trainer\"):\n",
    "    trainer = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_model, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 -> Accuracy 0.4827\n",
      "Step 1 -> Accuracy 0.5802\n",
      "Step 2 -> Accuracy 0.6134\n",
      "Step 3 -> Accuracy 0.6293\n",
      "Step 4 -> Accuracy 0.6181\n",
      "Step 5 -> Accuracy 0.6384\n",
      "Step 6 -> Accuracy 0.6351\n",
      "Step 7 -> Accuracy 0.6508\n",
      "Step 8 -> Accuracy 0.6507\n",
      "Step 9 -> Accuracy 0.6637\n",
      "Step 10 -> Accuracy 0.6561\n",
      "Step 11 -> Accuracy 0.6638\n",
      "Step 12 -> Accuracy 0.6715\n",
      "Step 13 -> Accuracy 0.6825\n",
      "Step 14 -> Accuracy 0.6814\n",
      "Step 15 -> Accuracy 0.6821\n",
      "Step 16 -> Accuracy 0.6898\n",
      "Step 17 -> Accuracy 0.6969\n",
      "Step 18 -> Accuracy 0.7089\n",
      "Step 19 -> Accuracy 0.7125\n",
      "Step 20 -> Accuracy 0.7246\n",
      "Step 21 -> Accuracy 0.7245\n",
      "Step 22 -> Accuracy 0.7231\n",
      "Step 23 -> Accuracy 0.7255\n",
      "Step 24 -> Accuracy 0.7261\n",
      "Step 25 -> Accuracy 0.726\n",
      "Step 26 -> Accuracy 0.7265\n",
      "Step 27 -> Accuracy 0.7294\n",
      "Step 28 -> Accuracy 0.7318\n",
      "Step 29 -> Accuracy 0.7334\n",
      "Step 30 -> Accuracy 0.7329\n",
      "Step 31 -> Accuracy 0.7371\n",
      "Step 32 -> Accuracy 0.7384\n",
      "Step 33 -> Accuracy 0.7421\n",
      "Step 34 -> Accuracy 0.7429\n",
      "Step 35 -> Accuracy 0.745\n",
      "Step 36 -> Accuracy 0.7457\n",
      "Step 37 -> Accuracy 0.7447\n",
      "Step 38 -> Accuracy 0.7473\n",
      "Step 39 -> Accuracy 0.7471\n",
      "Step 40 -> Accuracy 0.7478\n",
      "Step 41 -> Accuracy 0.7496\n",
      "Step 42 -> Accuracy 0.751\n",
      "Step 43 -> Accuracy 0.7547\n",
      "Step 44 -> Accuracy 0.7546\n",
      "Step 45 -> Accuracy 0.7547\n",
      "Step 46 -> Accuracy 0.7546\n",
      "Step 47 -> Accuracy 0.7559\n",
      "Step 48 -> Accuracy 0.7565\n",
      "Step 49 -> Accuracy 0.757\n",
      "Step 50 -> Accuracy 0.758\n",
      "Step 51 -> Accuracy 0.7604\n",
      "Step 52 -> Accuracy 0.759\n",
      "Step 53 -> Accuracy 0.7607\n",
      "Step 54 -> Accuracy 0.7608\n",
      "Step 55 -> Accuracy 0.7616\n",
      "Step 56 -> Accuracy 0.7612\n",
      "Step 57 -> Accuracy 0.7617\n",
      "Step 58 -> Accuracy 0.7627\n",
      "Step 59 -> Accuracy 0.7615\n",
      "Step 60 -> Accuracy 0.7621\n",
      "Step 61 -> Accuracy 0.7637\n",
      "Step 62 -> Accuracy 0.7646\n",
      "Step 63 -> Accuracy 0.7659\n",
      "Step 64 -> Accuracy 0.7658\n",
      "Step 65 -> Accuracy 0.7672\n",
      "Step 66 -> Accuracy 0.7677\n",
      "Step 67 -> Accuracy 0.7682\n",
      "Step 68 -> Accuracy 0.7678\n",
      "Step 69 -> Accuracy 0.7684\n",
      "Step 70 -> Accuracy 0.7715\n",
      "Step 71 -> Accuracy 0.7712\n",
      "Step 72 -> Accuracy 0.7733\n",
      "Step 73 -> Accuracy 0.7727\n",
      "Step 74 -> Accuracy 0.7757\n",
      "Step 75 -> Accuracy 0.7764\n",
      "Step 76 -> Accuracy 0.7774\n",
      "Step 77 -> Accuracy 0.7784\n",
      "Step 78 -> Accuracy 0.7808\n",
      "Step 79 -> Accuracy 0.7796\n",
      "Step 80 -> Accuracy 0.7808\n",
      "Step 81 -> Accuracy 0.782\n",
      "Step 82 -> Accuracy 0.7834\n",
      "Step 83 -> Accuracy 0.784\n",
      "Step 84 -> Accuracy 0.7847\n",
      "Step 85 -> Accuracy 0.7843\n",
      "Step 86 -> Accuracy 0.785\n",
      "Step 87 -> Accuracy 0.7854\n",
      "Step 88 -> Accuracy 0.7868\n",
      "Step 89 -> Accuracy 0.7848\n",
      "Step 90 -> Accuracy 0.7861\n",
      "Step 91 -> Accuracy 0.784\n",
      "Step 92 -> Accuracy 0.783\n",
      "Step 93 -> Accuracy 0.7853\n",
      "Step 94 -> Accuracy 0.786\n",
      "Step 95 -> Accuracy 0.7872\n",
      "Step 96 -> Accuracy 0.7877\n",
      "Step 97 -> Accuracy 0.7885\n",
      "Step 98 -> Accuracy 0.7905\n",
      "Step 99 -> Accuracy 0.7908\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #Training\n",
    "        \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Summary writer for TensorBoad  \n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(working_dir + 'train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(working_dir + 'test')\n",
    "    \n",
    "    for i in range(100):\n",
    "        #if i % 10 == 0:\n",
    "        x_data, y_data = mnist.train.next_batch(1000)\n",
    "        summary, _ = sess.run([merged_summary, trainer], feed_dict={x: x_data, y_: y_data})\n",
    "        train_writer.add_summary(summary, i)\n",
    "        #else:\n",
    "        summary, acc = sess.run([merged_summary, accuracy], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        test_writer.add_summary(summary, i)\n",
    "        print('Step %s -> Accuracy %s' % (i, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy = 92.02%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
